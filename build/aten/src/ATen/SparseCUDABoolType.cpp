// required for old g++ to compile PRId64 macros, see
// https://github.com/pytorch/pytorch/issues/3571
// for context
#define __STDC_FORMAT_MACROS

#include <ATen/SparseCUDABoolType.h>

// @generated by aten/src/ATen/gen.py

#include <ATen/CUDAGenerator.h>
#include <c10/core/Allocator.h>
#include <ATen/DeviceGuard.h>
#include <ATen/NativeFunctions.h>
#include <ATen/Utils.h>
#include <ATen/WrapDimUtils.h>
#include <c10/util/Half.h>
#include <c10/core/UndefinedTensorImpl.h>
#include <c10/util/Optional.h>

#include <cstddef>
#include <functional>
#include <memory>
#include <utility>

#include <ATen/Config.h>
#include <ATen/DeviceGuard.h>
#include <ATen/cuda/ATenCUDAGeneral.h>
#include <ATen/cuda/CUDADevice.h>
#include <ATen/cuda/CUDATypeDefault.h>

namespace at {

SparseCUDABoolType::SparseCUDABoolType()
  : CUDATypeDefault(SparseCUDATensorId(), /*is_variable=*/false, /*is_undefined=*/false) {}
ScalarType SparseCUDABoolType::scalarType() const {
  return ScalarType::Bool;
}
caffe2::TypeMeta SparseCUDABoolType::typeMeta() const {
  return caffe2::TypeMeta::Make<uint8_t>();
}
Backend SparseCUDABoolType::backend() const {
  return Backend::SparseCUDA;
}

const char * SparseCUDABoolType::toString() const {
  return "SparseCUDABoolType";
}

TypeID SparseCUDABoolType::ID() const {
  return TypeID::SparseCUDABool;
}

size_t SparseCUDABoolType::elementSizeInBytes() const {
  return sizeof(uint8_t);
}



}
