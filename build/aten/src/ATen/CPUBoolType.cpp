// required for old g++ to compile PRId64 macros, see
// https://github.com/pytorch/pytorch/issues/3571
// for context
#define __STDC_FORMAT_MACROS

#include <ATen/CPUBoolType.h>

// @generated by aten/src/ATen/gen.py

#include <TH/TH.h>
#include <TH/THTensor.hpp>
#include <THNN/THNN.h>
#undef THNN_
#include <c10/core/TensorImpl.h>
#include <ATen/CPUGenerator.h>
#include <c10/core/Allocator.h>
#include <ATen/DeviceGuard.h>
#include <ATen/NativeFunctions.h>
#include <ATen/Utils.h>
#include <ATen/WrapDimUtils.h>
#include <c10/util/Half.h>
#include <c10/core/TensorImpl.h>
#include <c10/core/UndefinedTensorImpl.h>
#include <c10/util/Optional.h>

#include <cstddef>
#include <functional>
#include <memory>
#include <utility>

#include <ATen/Config.h>


namespace at {

CPUBoolType::CPUBoolType()
  : CPUTypeDefault(CPUTensorId(), /*is_variable=*/false, /*is_undefined=*/false) {}

ScalarType CPUBoolType::scalarType() const {
  return ScalarType::Bool;
}

caffe2::TypeMeta CPUBoolType::typeMeta() const {
    return caffe2::TypeMeta::Make<uint8_t>();
}

Backend CPUBoolType::backend() const {
  return Backend::CPU;
}

const char * CPUBoolType::toString() const {
  return "CPUBoolType";
}

TypeID CPUBoolType::ID() const {
  return TypeID::CPUBool;
}

size_t CPUBoolType::elementSizeInBytes() const {
  return sizeof(uint8_t);
}

/* example
Tensor * CPUBoolType::add(Tensor & a, Tensor & b) {
  std::cout << "add CPUBoolTensor\n";
  return &a;
}
*/



}
