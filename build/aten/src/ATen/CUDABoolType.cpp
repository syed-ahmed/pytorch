// required for old g++ to compile PRId64 macros, see
// https://github.com/pytorch/pytorch/issues/3571
// for context
#define __STDC_FORMAT_MACROS

#include <ATen/CUDABoolType.h>

// @generated by aten/src/ATen/gen.py

#include <THC/THC.h>
#include <THC/THCTensor.hpp>
#include <THCUNN/THCUNN.h>
#undef THNN_
#undef THCIndexTensor_
#include <c10/core/TensorImpl.h>
#include <ATen/CUDAGenerator.h>
#include <c10/core/Allocator.h>
#include <ATen/DeviceGuard.h>
#include <ATen/NativeFunctions.h>
#include <ATen/Utils.h>
#include <ATen/WrapDimUtils.h>
#include <c10/util/Half.h>
#include <c10/core/TensorImpl.h>
#include <c10/core/UndefinedTensorImpl.h>
#include <c10/util/Optional.h>

#include <cstddef>
#include <functional>
#include <memory>
#include <utility>

#include <ATen/Config.h>
#include <ATen/DeviceGuard.h>
#include <ATen/cuda/ATenCUDAGeneral.h>
#include <ATen/cuda/CUDADevice.h>
#include <ATen/cuda/CUDATypeDefault.h>

namespace at {

CUDABoolType::CUDABoolType()
  : CUDATypeDefault(CUDATensorId(), /*is_variable=*/false, /*is_undefined=*/false) {}

ScalarType CUDABoolType::scalarType() const {
  return ScalarType::Bool;
}

caffe2::TypeMeta CUDABoolType::typeMeta() const {
    return caffe2::TypeMeta::Make<uint8_t>();
}

Backend CUDABoolType::backend() const {
  return Backend::CUDA;
}

const char * CUDABoolType::toString() const {
  return "CUDABoolType";
}

TypeID CUDABoolType::ID() const {
  return TypeID::CUDABool;
}

size_t CUDABoolType::elementSizeInBytes() const {
  return sizeof(uint8_t);
}

/* example
Tensor * CUDABoolType::add(Tensor & a, Tensor & b) {
  std::cout << "add CUDABoolTensor\n";
  return &a;
}
*/



}
